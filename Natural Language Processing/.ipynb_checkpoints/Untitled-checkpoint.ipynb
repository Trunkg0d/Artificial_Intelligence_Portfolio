{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33216317-55b0-4b1b-a4ec-ec9a5da5ede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c309fe-eaca-455f-9ecf-cc6ecf564020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce96d834-30de-4bfa-9fe9-12ca15bba510",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = open(path_to_file, \"rb\").read().decode(encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7627ca-8730-4033-afd3-847f578bd1dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2557f56a-740c-41a5-8be7-11f10fff4e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "char2idx = {u: i for i, u in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782a177c-b321-48ca-a4ea-ff7e7ed1e5ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx2char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c422239e-7a6d-484c-954a-e392d4539267",
   "metadata": {},
   "source": [
    "And we convert the characters in the downloaded Shakespear text into a long sequence of integer indexes. We slice and batch it to create the dataset \"sequences\". Next, we create a dataset with an additional field holding the target text as the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce83b49-3e17-497a-8d62-9c552c42ea52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_as_int  = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480c4ebd-cea9-4039-8539-fa0701482b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The maximum length sentence for a single input in characters\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text) // (seq_length + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d529b8-0357-4820-9de9-77832090f536",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(test_as_int)\n",
    "\n",
    "sequences = char_dataset.batch(seq_length + 1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786cd78a-2af8-469f-a3f7-9d03aac20d7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the target text by left shift of one character\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad3f72e-4c9f-4f23-9c2f-8894c1932c0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d815a7c-cf11-4898-a265-3970da92bfbe",
   "metadata": {},
   "source": [
    "Then, we shuffle and batch the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0966f2f-5549-40a3-8a82-179b2163b280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create training batches\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possible infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9e5f30-6923-4750-9424-3bc36cb8baad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb0322e-d906-4bff-a555-aea38ab5d84e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077de970-81a7-471a-9c31-2e7ca5e870c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, \n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer=\"glorot_uniform\"),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c028015a-0a4a-40be-a8e4-d062d11b343c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1296635-49ed-41cd-9ee7-c43c46b30448",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d72561-2ee6-464d-9666-9f4b39bdc177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346d2f00-f10a-4c29-a026-5490e7e07b02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3451d58-33e1-4618-924e-1990d0e2bb3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c971cd-2810-4242-9af3-fd2d2cfca8c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c1bf7a-e0d8-4746-93d9-689f6a2fe99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    num_generate = 1000\n",
    "    input_eval = line_to_tensor(start_string)\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    temparature = 1.0\n",
    "    \n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        predictions = predictions / temparature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(chr(predicted_id))\n",
    "    \n",
    "    return start_string + ''.join(text_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3425d01d-8a03-44fe-8303-270b5d49d525",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(generate_text(model, start_string=u\"ROMMEO: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e4acbc-02a9-4938-93b6-80c219331d24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
