{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33216317-55b0-4b1b-a4ec-ec9a5da5ede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce96d834-30de-4bfa-9fe9-12ca15bba510",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "text = open(path_to_file, \"rb\").read().decode(encoding=\"utf-8\")\n",
    "vocab = sorted(set(text))\n",
    "char2idx = {u: i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "012250b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?',\n",
       "        'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
       "        'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
       "        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
       "        'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'],\n",
       "       dtype='<U1'),\n",
       " ['\\n',\n",
       "  ' ',\n",
       "  '!',\n",
       "  '$',\n",
       "  '&',\n",
       "  \"'\",\n",
       "  ',',\n",
       "  '-',\n",
       "  '.',\n",
       "  '3',\n",
       "  ':',\n",
       "  ';',\n",
       "  '?',\n",
       "  'A',\n",
       "  'B',\n",
       "  'C',\n",
       "  'D',\n",
       "  'E',\n",
       "  'F',\n",
       "  'G',\n",
       "  'H',\n",
       "  'I',\n",
       "  'J',\n",
       "  'K',\n",
       "  'L',\n",
       "  'M',\n",
       "  'N',\n",
       "  'O',\n",
       "  'P',\n",
       "  'Q',\n",
       "  'R',\n",
       "  'S',\n",
       "  'T',\n",
       "  'U',\n",
       "  'V',\n",
       "  'W',\n",
       "  'X',\n",
       "  'Y',\n",
       "  'Z',\n",
       "  'a',\n",
       "  'b',\n",
       "  'c',\n",
       "  'd',\n",
       "  'e',\n",
       "  'f',\n",
       "  'g',\n",
       "  'h',\n",
       "  'i',\n",
       "  'j',\n",
       "  'k',\n",
       "  'l',\n",
       "  'm',\n",
       "  'n',\n",
       "  'o',\n",
       "  'p',\n",
       "  'q',\n",
       "  'r',\n",
       "  's',\n",
       "  't',\n",
       "  'u',\n",
       "  'v',\n",
       "  'w',\n",
       "  'x',\n",
       "  'y',\n",
       "  'z'],\n",
       " 65)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2char, vocab, len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ce83b49-3e17-497a-8d62-9c552c42ea52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_as_int  = np.array([char2idx[c] for c in text])\n",
    "\n",
    "# The maximum length sentence for a single input in characters\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text) // (seq_length + 1)\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(test_as_int)\n",
    "\n",
    "sequences = char_dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "# Create the target text by left shift of one character\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ad3f72e-4c9f-4f23-9c2f-8894c1932c0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec=(TensorSpec(shape=(100,), dtype=tf.int32, name=None), TensorSpec(shape=(100,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0966f2f-5549-40a3-8a82-179b2163b280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create training batches\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possible infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a9e5f30-6923-4750-9424-3bc36cb8baad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int32, name=None), TensorSpec(shape=(64, 100), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a3efd72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b663e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '$',\n",
       " '&',\n",
       " \"'\",\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '3',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7cb0322e-d906-4bff-a555-aea38ab5d84e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 512\n",
    "\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, \n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer=\"glorot_uniform\"),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1296635-49ed-41cd-9ee7-c43c46b30448",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "172/172 [==============================] - 100s 557ms/step - loss: 2.7388\n",
      "Epoch 2/10\n",
      "172/172 [==============================] - 111s 639ms/step - loss: 2.0640\n",
      "Epoch 3/10\n",
      "172/172 [==============================] - 98s 561ms/step - loss: 1.8087\n",
      "Epoch 4/10\n",
      "172/172 [==============================] - 115s 662ms/step - loss: 1.6535\n",
      "Epoch 5/10\n",
      "172/172 [==============================] - 122s 698ms/step - loss: 1.5580\n",
      "Epoch 6/10\n",
      "172/172 [==============================] - 121s 697ms/step - loss: 1.4961\n",
      "Epoch 7/10\n",
      "172/172 [==============================] - 117s 670ms/step - loss: 1.4505\n",
      "Epoch 8/10\n",
      "172/172 [==============================] - 115s 659ms/step - loss: 1.4163\n",
      "Epoch 9/10\n",
      "172/172 [==============================] - 116s 665ms/step - loss: 1.3883\n",
      "Epoch 10/10\n",
      "172/172 [==============================] - 128s 735ms/step - loss: 1.3650\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=loss)\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bba70098",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09c1bf7a-e0d8-4746-93d9-689f6a2fe99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    num_generate = 1000\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    temparature = 1.0\n",
    "    text_generated = []\n",
    "    \n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        predictions = predictions / temparature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "    \n",
    "    return start_string + ''.join(text_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3425d01d-8a03-44fe-8303-270b5d49d525",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMMEO: 'tis to be the very commons:\n",
      "And mark for an incle where verit down to chide your lords, and the other growing\n",
      "When my dew justice for you:\n",
      "Say how she calmel and his house!\n",
      "\n",
      "VOLUMNIA:\n",
      "Having not of bann'd and ear;\n",
      "In the marchionest man, with her see she's gentleman of all the just,\n",
      "As with her chairs would let him no more reforence\n",
      "Are yet be lew'd thee how I wofe to make me:\n",
      "Know too did? i' the drimble; and, darge me let\n",
      "ist worthing arms.\n",
      "Be Gaunty are the point 'sway.\n",
      "\n",
      "GONZALO:\n",
      "Let me is he does pardented it with ayon.\n",
      "\n",
      "all God's welcome: this friend's cur die.\n",
      "\n",
      "CATESBY:\n",
      "Then for me which you will with me and to die:\n",
      "For my grave I'll goes to be past a lag soil in the virtue. Pete,\n",
      "Which, but stead root to consum title.\n",
      "\n",
      "PRINCE Sir. She letters in the prosonest unprisines, if you cand him yet\n",
      "As your kindred brownen wring their scorces,\n",
      "To show with her many days:\n",
      "Anstink of my head my lord.\n",
      "\n",
      "BIANCA:\n",
      "Not I.\n",
      "\n",
      "Servant:\n",
      "And, to steely wag cape.\n",
      "\n",
      "MENENIUS:\n",
      "But nown your, is with a wo\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"ROMMEO: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e4acbc-02a9-4938-93b6-80c219331d24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-TF2.0",
   "language": "python",
   "name": "py3-tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
