{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b056762d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 12:03:28.857695: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-07 12:03:29.638064: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69869864-5069-4d7a-b2e1-0935f2b80627",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "text = open(path_to_file, \"rb\").read().decode(encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "953ada90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_vocab(text):\n",
    "    vocab = {}\n",
    "    idx2char = []\n",
    "    \n",
    "    for char in text:\n",
    "        if char not in vocab:\n",
    "            vocab[char] = len(vocab)\n",
    "            idx2char.append(char)\n",
    "    return vocab, idx2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27098c34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'F': 0,\n",
       "  'i': 1,\n",
       "  'r': 2,\n",
       "  's': 3,\n",
       "  't': 4,\n",
       "  ' ': 5,\n",
       "  'C': 6,\n",
       "  'z': 7,\n",
       "  'e': 8,\n",
       "  'n': 9,\n",
       "  ':': 10,\n",
       "  '\\n': 11,\n",
       "  'B': 12,\n",
       "  'f': 13,\n",
       "  'o': 14,\n",
       "  'w': 15,\n",
       "  'p': 16,\n",
       "  'c': 17,\n",
       "  'd': 18,\n",
       "  'a': 19,\n",
       "  'y': 20,\n",
       "  'u': 21,\n",
       "  'h': 22,\n",
       "  ',': 23,\n",
       "  'm': 24,\n",
       "  'k': 25,\n",
       "  '.': 26,\n",
       "  'A': 27,\n",
       "  'l': 28,\n",
       "  'S': 29,\n",
       "  'Y': 30,\n",
       "  'v': 31,\n",
       "  '?': 32,\n",
       "  'R': 33,\n",
       "  'M': 34,\n",
       "  'W': 35,\n",
       "  \"'\": 36,\n",
       "  'L': 37,\n",
       "  'I': 38,\n",
       "  'N': 39,\n",
       "  'g': 40,\n",
       "  ';': 41,\n",
       "  'b': 42,\n",
       "  '!': 43,\n",
       "  'O': 44,\n",
       "  'j': 45,\n",
       "  'V': 46,\n",
       "  '-': 47,\n",
       "  'T': 48,\n",
       "  'H': 49,\n",
       "  'E': 50,\n",
       "  'U': 51,\n",
       "  'D': 52,\n",
       "  'P': 53,\n",
       "  'q': 54,\n",
       "  'x': 55,\n",
       "  'J': 56,\n",
       "  'G': 57,\n",
       "  'K': 58,\n",
       "  'Q': 59,\n",
       "  '&': 60,\n",
       "  'Z': 61,\n",
       "  'X': 62,\n",
       "  '3': 63,\n",
       "  '$': 64},\n",
       " 65)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab, idx2char = create_vocab(text)\n",
    "vocab, len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f0f95bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2, ..., 40, 26, 11])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_tensor_data(text, vocab):\n",
    "    tensor_data = []\n",
    "    \n",
    "    for char in text:\n",
    "        tensor_data.append(vocab[char])\n",
    "            \n",
    "    return np.array(tensor_data)\n",
    "\n",
    "tensor_data = create_tensor_data(text, vocab)\n",
    "tensor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcc40c2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 12:05:54.992033: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-07 12:05:54.992245: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-07 12:05:55.383687: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(tensor_data)\n",
    "sequences = char_dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    \n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69049fb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(TensorSpec(shape=(100,), dtype=tf.int64, name=None), TensorSpec(shape=(100,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = sequences.map(split_input_target)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37731038",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "buffer_size = 10000\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f6ab1af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 512\n",
    "gru_units = 2\n",
    "\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, gru_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape = [batch_size, None]),\n",
    "    ])\n",
    "    \n",
    "    for gru_unit in range(gru_units):\n",
    "        model.add(tf.keras.layers.GRU(units=rnn_units,\n",
    "                                     return_sequences=True,\n",
    "                                     stateful=True,\n",
    "                                     recurrent_initializer=\"glorot_uniform\"))\n",
    "    model.add(tf.keras.layers.Dense(vocab_size))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b109395",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (64, None, 256)           16640     \n",
      "                                                                 \n",
      " gru (GRU)                   (64, None, 512)           1182720   \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (64, None, 512)           1575936   \n",
      "                                                                 \n",
      " dense (Dense)               (64, None, 65)            33345     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2808641 (10.71 MB)\n",
      "Trainable params: 2808641 (10.71 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, gru_units, batch_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82ed61eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee1e0869",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4267574a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "172/172 [==============================] - 88s 499ms/step - loss: 2.4758\n",
      "Epoch 2/10\n",
      "172/172 [==============================] - 87s 500ms/step - loss: 1.7942\n",
      "Epoch 3/10\n",
      "172/172 [==============================] - 87s 500ms/step - loss: 1.5744\n",
      "Epoch 4/10\n",
      "172/172 [==============================] - 87s 500ms/step - loss: 1.4706\n",
      "Epoch 5/10\n",
      "172/172 [==============================] - 87s 500ms/step - loss: 1.4083\n",
      "Epoch 6/10\n",
      "172/172 [==============================] - 87s 501ms/step - loss: 1.3645\n",
      "Epoch 7/10\n",
      "172/172 [==============================] - 87s 500ms/step - loss: 1.3286\n",
      "Epoch 8/10\n",
      "172/172 [==============================] - 87s 501ms/step - loss: 1.3001\n",
      "Epoch 9/10\n",
      "172/172 [==============================] - 87s 501ms/step - loss: 1.2720\n",
      "Epoch 10/10\n",
      "172/172 [==============================] - 87s 501ms/step - loss: 1.2479\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir = './training_checkpoints_custom'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19dc8760",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, 2, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b8df7ed-e605-4b7a-b5d2-86d1f8c9fdca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    num_generate = 1000\n",
    "    input_eval = [vocab[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    temparature = 1.0\n",
    "    text_generated = []\n",
    "    \n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        predictions = predictions / temparature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "    \n",
    "    return start_string + ''.join(text_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61c81cd3-1388-4544-ae16-3a871b549a3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMMEO: Juliet, whither:\n",
      "and I am not spyed eyes,\n",
      "The rabble is farties: be great to partly,\n",
      "And with stlable and roses I know your sister; and\n",
      "\n",
      "ISABELLA:\n",
      "I thank your alms\n",
      "As any of this had been a random flourishet.\n",
      "Why, soo hope; gentle AUMERLE:\n",
      "I know you never entertain'd his wretched dipolts\n",
      "I looked about thee term, nor rough.\n",
      "I'll weep their graved fight we go?\n",
      "Now, sir, they come those country; your lady,\n",
      "Nor the hand of even, al oft that your patience:\n",
      "Your figure thee that after men?\n",
      "\n",
      "First Moststand\n",
      "to me.\n",
      "\n",
      "PROSPERO:\n",
      "Thou'lengs his writing here,\n",
      "We will wish you, Whose ish closalio, for he remain\n",
      "I forget with thee.\n",
      "\n",
      "FRIART MECHICHARD II:\n",
      "Lack not how, at home and here,\n",
      "Being not so froward to thy bed!\n",
      "\n",
      "PRINCE EDWARD:\n",
      "My gracious Glouces, with his oracle:\n",
      "As other babes,\n",
      "I prove what can find your lordship to pray ye.\n",
      "Why, if this torment them; what's a-groal to have scorn Forbid his knowledge.\n",
      "\n",
      "BIANDA:\n",
      "Noble lord! Poor you that favours Mowbray?\n",
      "\n",
      "AUTOLYCUS:\n",
      "By gates and princely in\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"ROMMEO: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d9baacc-ae7c-4f99-8fd9-3c0dca56f76e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hellow, then wash'd nor part.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "But, Montague unquired here!, and knock our mother;\n",
      "God from the first brail her, and the abfession of the earth have show'd top the\n",
      "next knows with my brother, fair\n",
      "Say our friends pove them hope as you,\n",
      "That will the peace of your wild as\n",
      "You ratry himself at Bohemia: within it straight\n",
      "I' the people--my lord,\n",
      "Go one thine enemy's fruitted in my father.\n",
      "Look and am that, even he does speak with the ground\n",
      "And know.\n",
      "\n",
      "BEANCA:\n",
      "Bf this foul came is the last?\n",
      "The penitently gar, the napul creatures of triumph.\n",
      "\n",
      "MENENIUS:\n",
      "Ay, as, that you well.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "\n",
      "Second Gentleman:\n",
      "Let 't straight.\n",
      "\n",
      "First Lady:\n",
      "Part thee to be thought untishes,\n",
      "So hear it pass'd!\n",
      "\n",
      "CLIOF EDWARD IV:\n",
      "And yet I belime these own!\n",
      "Who travels and not thee; where has but with a purpose.\n",
      "\n",
      "DUKE OF YORK:\n",
      "What a day look upon me: thou, sir, your mother care?\n",
      "\n",
      "Lord Messenger:\n",
      "That gives at ons, camberle, he'll give\n",
      "with me two fancy, sit to change the crown.\n",
      "\n",
      "KATHARINA:\n",
      "True, wh\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=\"Hello\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a312199c-538a-496f-8a7c-d26af0b298f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_kernel",
   "language": "python",
   "name": "test_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
